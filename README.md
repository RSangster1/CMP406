Task 1 used hive to create and query tables to the clients request such as salary, number of staff per department and staff working full or part time.
The data was imported into a table made in HiveQL and added in primary keys to all staff.
Task 2 required the creation of a Hadoop HDFS cluster of the master node and 3 workers and configuring Spark.
Each nodes IP, hostname and config files were made and formatted.
A simple scala application to idenfify what language a txt file was written in was used to test if the installation was working and spark was correctly implemented.

![image](https://github.com/RSangster1/CMP406/assets/114151269/749c6516-eb52-450f-989f-768b07d02cc4)


![image](https://github.com/RSangster1/CMP406/assets/114151269/6e8355ff-e44a-4d3d-88f7-4ca5d4f48c16)
